{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL para la tabla review\n",
    " Se recorre el archivo \"review.json\" para construir nuevos archivos .parque  \n",
    "  clasificando por a単o, se identifico que la data va desde 2005 hasta 2022, \n",
    "  por lo tanto se tendran 17 archivos de la forma ... review2019.csv, review2020.csv ... \n",
    " nota = En la carpeta donde se ejecuta debe estar el archivo \"review.json\" y \n",
    "        no deben estar archivos review20XX.csv de corridas anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias a utilizar\n",
    "import pandas as pd \n",
    "from IPython.display import clear_output\n",
    "import os \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new directory is created!\n"
     ]
    }
   ],
   "source": [
    "#Dise単ado para leer el archivo con el nombre indicado para carga incremental \n",
    "# simplemente colocar el archivo .json con el nombre indicado.\n",
    "\n",
    "nombre = 'review' \n",
    "path = os.path.abspath(os.getcwd())+\"\\\\review_\"+datetime.now().strftime(\"%d_%m_%Y_%H-%M\")\n",
    "\n",
    "# Check whether the specified path exists or not\n",
    "if not os.path.exists(path):\n",
    "    # Create a new directory because it does not exist \n",
    "  os.makedirs(path,exist_ok=False)\n",
    "  print(\"The new directory is created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completado Etapa 1: 35/35  100.0%\n",
      "actualizando c:\\Henry\\LABS_01\\221114_GroupLab\\JHO\\review_23_11_2022_15-05\\review_2005.csv\n",
      "actualizando c:\\Henry\\LABS_01\\221114_GroupLab\\JHO\\review_23_11_2022_15-05\\review_2006.csv\n",
      "actualizando c:\\Henry\\LABS_01\\221114_GroupLab\\JHO\\review_23_11_2022_15-05\\review_2007.csv\n",
      "actualizando c:\\Henry\\LABS_01\\221114_GroupLab\\JHO\\review_23_11_2022_15-05\\review_2008.csv\n",
      "actualizando c:\\Henry\\LABS_01\\221114_GroupLab\\JHO\\review_23_11_2022_15-05\\review_2009.csv\n",
      "actualizando c:\\Henry\\LABS_01\\221114_GroupLab\\JHO\\review_23_11_2022_15-05\\review_2010.csv\n",
      "actualizando c:\\Henry\\LABS_01\\221114_GroupLab\\JHO\\review_23_11_2022_15-05\\review_2011.csv\n",
      "actualizando c:\\Henry\\LABS_01\\221114_GroupLab\\JHO\\review_23_11_2022_15-05\\review_2012.csv\n",
      "actualizando c:\\Henry\\LABS_01\\221114_GroupLab\\JHO\\review_23_11_2022_15-05\\review_2013.csv\n",
      "actualizando c:\\Henry\\LABS_01\\221114_GroupLab\\JHO\\review_23_11_2022_15-05\\review_2014.csv\n",
      "actualizando c:\\Henry\\LABS_01\\221114_GroupLab\\JHO\\review_23_11_2022_15-05\\review_2015.csv\n",
      "actualizando c:\\Henry\\LABS_01\\221114_GroupLab\\JHO\\review_23_11_2022_15-05\\review_2016.csv\n",
      "actualizando c:\\Henry\\LABS_01\\221114_GroupLab\\JHO\\review_23_11_2022_15-05\\review_2017.csv\n",
      "actualizando c:\\Henry\\LABS_01\\221114_GroupLab\\JHO\\review_23_11_2022_15-05\\review_2018.csv\n",
      "actualizando c:\\Henry\\LABS_01\\221114_GroupLab\\JHO\\review_23_11_2022_15-05\\review_2019.csv\n",
      "actualizando c:\\Henry\\LABS_01\\221114_GroupLab\\JHO\\review_23_11_2022_15-05\\review_2020.csv\n",
      "actualizando c:\\Henry\\LABS_01\\221114_GroupLab\\JHO\\review_23_11_2022_15-05\\review_2021.csv\n",
      "actualizando c:\\Henry\\LABS_01\\221114_GroupLab\\JHO\\review_23_11_2022_15-05\\review_2022.csv\n"
     ]
    }
   ],
   "source": [
    "# Organizar la informacion Carga de datos\n",
    "# Se recorre el archivo \"review.json\" para construir nuevos .csv  \n",
    "#  clasificando por a単o, se identifico que la data va desde 2005 hasta 2022, \n",
    "#  por lo tanto se tendran 17 archivos de la forma ... review2019.csv, review2020.csv ... \n",
    "# nota = En la carpeta donde se ejecuta debe estar el archivo \"review.json\" y \n",
    "#        no deben estar archivos review20XX.csv de corridas anteriores\n",
    "#Tiempo de ejecucion aprox 15min si se elimina la limpieza final (eliminar ducplicados) <9min\n",
    "\n",
    "import pandas as pd \n",
    "from IPython.display import clear_output\n",
    "import os \n",
    "\n",
    "def cargaIncremental(df,nombre ='review'):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    for year in range(2005,2023):\n",
    "        if os.path.isfile(path+'\\\\'+nombre+\"_\"+str(year)+\".csv\"):\n",
    "            #Carga incremental de datos en .csv\n",
    "            print('actualizando '+path+'\\\\'+nombre+\"_\"+str(year)+\".csv\")\n",
    "            filtered_df = df.loc[df['date'].dt.year == year]\n",
    "            filtered_df.to_csv(path+'\\\\'+nombre+\"_\"+str(year)+\".csv\",mode='a', index=False, header=False)\n",
    "        else:\n",
    "            #Primera corrida\n",
    "            print('creando '+nombre+\"_\"+str(year)+\".csv\")\n",
    "            filtered_df = df.loc[df['date'].dt.year == year]\n",
    "            filtered_df.to_csv(path+'\\\\'+nombre+\"_\"+str(year)+\".csv\",index=False)\n",
    "\n",
    "total = 0 \n",
    "cont = 0\n",
    "cont_max = 35  #Se sabe que tama単o +200k  se haran 35 partes (chunk) del .json \n",
    "\n",
    "Tamano = 200000\n",
    "# Se recorre por partes el archivo .json\n",
    "for chunk in pd.read_json(nombre+\".json\",chunksize=Tamano, lines=True):\n",
    "        # Visualizacion de avance\n",
    "        cont = cont + 1\n",
    "        clear_output(wait=True)\n",
    "        print('Completado Etapa 1: '+str(cont)+\"/\"+str(cont_max)+\"  \"+ str(round(cont / cont_max * 100, 2)) + '%')\n",
    "        \n",
    "        #Se carga la parte\n",
    "        cargaIncremental(chunk)\n",
    "\n",
    "#Tiempo esperado de corrida: 8 min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completado Etapa 2: 18/18  100.0%\n",
      "review_2022.csv cambio de 31665  a  31665 columnas, se perdieron  0 columnas\n"
     ]
    }
   ],
   "source": [
    "#Borrando duplicados en caso de que existan\n",
    "cont = 0\n",
    "cont_max = 18 \n",
    "#Limpieza final\n",
    "for year in range(2005,2023):\n",
    "    # Visualizacion de avance\n",
    "    cont = cont + 1\n",
    "    clear_output(wait=True)\n",
    "    print('Completado Etapa 2: '+str(cont)+\"/\"+str(cont_max)+\"  \"+ str(round(cont / cont_max * 100, 2)) + '%')\n",
    "    \n",
    "    if os.path.isfile(path+'\\\\'+nombre+\"_\"+str(year)+\".csv\"):\n",
    "        #Revision de datos en .csv\n",
    "        df = pd.read_csv(path+'\\\\'+nombre+\"_\"+str(year)+\".csv\") \n",
    "        antes = df.shape[0]\n",
    "        filtered_df = df.drop_duplicates().reset_index(drop=True)\n",
    "        despues = filtered_df.shape[0]\n",
    "        print(nombre+\"_\"+str(year)+\".csv cambio de\",antes,\" a \",despues,\"columnas, se perdieron \",antes-despues,\"columnas\")\n",
    "        filtered_df.to_csv(path+'\\\\'+nombre+\"_\"+str(year)+\".csv\",index=False)\n",
    "        \n",
    "#Tiempo: 2 min si se hace despues de borrar la columna texto, sino tarda como 30 min. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completado Etapa: 18/18  100.0%\n"
     ]
    }
   ],
   "source": [
    "#Manejo de columna Texto\n",
    "#tiempo aprox \n",
    "def ETL_texto(df):\n",
    "    #Por ahora solo se borrara la columna texo\n",
    "    df.drop(columns=[\"text\"],inplace=True)\n",
    "\n",
    "cont = 0\n",
    "cont_max = 18 \n",
    "#Limpieza final\n",
    "for year in range(2005,2023):\n",
    "    # Visualizacion de avance\n",
    "    cont = cont + 1\n",
    "    clear_output(wait=True)\n",
    "    print('Completado Etapa: '+str(cont)+\"/\"+str(cont_max)+\"  \"+ str(round(cont / cont_max * 100, 2)) + '%')\n",
    "    \n",
    "    if os.path.isfile(path+'\\\\'+nombre+\"_\"+str(year)+\".csv\"):\n",
    "        #Revision de datos en .csv\n",
    "        df = pd.read_csv(path+'\\\\'+nombre+\"_\"+str(year)+\".csv\") \n",
    "        df.drop(columns=[\"text\"],inplace=True)\n",
    "        df.to_csv(path+'\\\\'+nombre+\"_\"+str(year)+\".csv\",index=False)\n",
    "#Tiempo: 3 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completado: 18/18  100.0%\n",
      "actualizando Iduser de c:\\Henry\\LABS_01\\221114_GroupLab\\JHO\\review_23_11_2022_15-05\\review_2022.csv\n"
     ]
    }
   ],
   "source": [
    "#Manejo de la columna user_id para cual se necesita el archivo codes_users.csv \n",
    "# creado desde \"user.json\" ....\n",
    "#users = pd.read_json(\"user.json\", lines=True , chunksize=200000) \n",
    "#cods_users = pd.concat(users).user_id\n",
    "#cods_users = cods_users.reset_index()\n",
    "#cods_users = cods_users.rename(columns={'index':'n_user_id'})\n",
    "#cods_users.to_csv(path+'\\\\'+'codes_users.csv', index=False)\n",
    "#tiempo: 3min \n",
    "\n",
    "def  cambio_Iduser(nombre_csv,derecha):\n",
    "    izquierda = pd.read_csv(nombre_csv) \n",
    "    result = izquierda.join(derecha, on='user_id')\n",
    "    result = result[['review_id', 'n_user_id', 'business_id', 'stars', 'useful', 'funny','cool', 'date']]\n",
    "    result = result.rename(columns={\"n_user_id\": \"Iduser\"})\n",
    "    print('actualizando Iduser de '+nombre_csv)\n",
    "    result.to_csv(nombre_csv,index=False)\n",
    "\n",
    "# Para visualizacion de avance\n",
    "cont = 0\n",
    "cont_max = 18 \n",
    "\n",
    "#Preparando join left\n",
    "codes_users = pd.read_csv('codes_users.csv')\n",
    "derecha = codes_users.set_index('user_id')\n",
    "\n",
    "for year in range(2005,2023):\n",
    "    # Visualizacion de avance\n",
    "    cont = cont + 1\n",
    "    clear_output(wait=True)\n",
    "    print('Completado: '+str(cont)+\"/\"+str(cont_max)+\"  \"+ str(round(cont / cont_max * 100, 2)) + '%')\n",
    "    \n",
    "    #Cambio 'userId'(str) en cada archivo reviewXXXX.csv por Iduser(int)\n",
    "    if os.path.isfile(path+'\\\\'+nombre+\"_\"+str(year)+\".csv\"):\n",
    "        cambio_Iduser(path+'\\\\'+nombre+\"_\"+str(year)+\".csv\",derecha)\n",
    " \n",
    "#tiempo: 2 min "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completado: 18/18  100.0%\n",
      "actualizando Iduser de c:\\Henry\\LABS_01\\221114_GroupLab\\JHO\\review_23_11_2022_15-05\\review_2022.csv\n"
     ]
    }
   ],
   "source": [
    "#Manejo de la columna business_id para cual se necesita el archivo Ibusiness_index.csv que \n",
    "# se obtiene de business.json ....\n",
    "#df_business = pd.read_json('business.json', lines=True)\n",
    "#business_index = pd.DataFrame()\n",
    "#business_index['id'] = list(range(0, len(df_business) + 1, 1))\n",
    "#business_index['business_id'] = df_business['business_id'].copy()\n",
    "#business_index.to_csv(\"business_index.csv\",index=False)\n",
    "\n",
    "def  cambio_Idbusiness(nombre_csv,derecha):\n",
    "    izquierda = pd.read_csv(nombre_csv) \n",
    "    result = izquierda.join(derecha, on='business_id')\n",
    "    result = result[['review_id', 'Iduser', 'id', 'stars', 'useful', 'funny','cool', 'date']]\n",
    "    result = result.rename(columns={\"id\": \"Idbusiness\"})\n",
    "    print('actualizando Iduser de '+nombre_csv)\n",
    "    result.to_csv(nombre_csv,index=False)\n",
    "\n",
    "# Para visualizacion de avance\n",
    "cont = 0\n",
    "cont_max = 18 \n",
    "\n",
    "#Preparando join left\n",
    "business_index = pd.read_csv(\"business_index.csv\")\n",
    "derecha = business_index.set_index('business_id')\n",
    "\n",
    "for year in range(2005,2023):\n",
    "    # Visualizacion de avance\n",
    "    cont = cont + 1\n",
    "    clear_output(wait=True)\n",
    "    print('Completado: '+str(cont)+\"/\"+str(cont_max)+\"  \"+ str(round(cont / cont_max * 100, 2)) + '%')\n",
    "    \n",
    "    #Cambio 'userId'(str) en cada archivo reviewXXXX.csv por Iduser(int)\n",
    "    if os.path.isfile(path+'\\\\'+nombre+\"_\"+str(year)+\".csv\"):\n",
    "        cambio_Idbusiness(path+'\\\\'+nombre+\"_\"+str(year)+\".csv\",derecha)\n",
    "\n",
    "#tiempo: 2 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completado: 18/18  100.0%\n",
      "actualizando Idreview.csv con c:\\Henry\\LABS_01\\221114_GroupLab\\JHO\\review_23_11_2022_15-05\\review_2022.csv\n"
     ]
    }
   ],
   "source": [
    "# Manejo de la columna Idreview \n",
    "# Codigo para ir leyendo los df \"review_20xx.csv\" e ir creando la tabla Idreview.csv\n",
    "\n",
    "def  creacion_Idreview(nombre_csv,indice=0):\n",
    "    df = pd.read_csv(nombre_csv) \n",
    "    \n",
    "    if os.path.isfile(path+'\\\\Idreview.csv'):\n",
    "        #Carga incremental de datos \n",
    "        print('actualizando Idreview.csv con '+nombre_csv)\n",
    "        #Se crea el nuevo \"Id_review\" en secuencia con anterior\n",
    "        lista = list(range(indice+1,indice+df.shape[0]+1))\n",
    "        nuevo_indice = lista[-1]\n",
    "        \n",
    "        df.insert(0,\"Id_review\",lista)\n",
    "        Idreview = df[[\"Id_review\",\"review_id\"]]\n",
    "        df.drop(columns=[\"review_id\"],inplace=True)\n",
    "        df.to_csv(nombre_csv,index=False)\n",
    "        Idreview.to_csv(path+'\\\\Idreview.csv',mode='a', index=False, header=False)\n",
    "    else:\n",
    "        #Primera corrida\n",
    "        print('creando Idreview.csv')\n",
    "        df.reset_index(inplace=True)\n",
    "        df = df.rename(columns={\"index\": \"Id_review\"})\n",
    "        Idreview = df[[\"Id_review\",\"review_id\"]]\n",
    "        df.drop(columns=[\"review_id\"],inplace=True)\n",
    "        df.to_csv(nombre_csv,index=False)\n",
    "        Idreview.to_csv(path+'\\\\Idreview.csv',index=False)\n",
    "        nuevo_indice =  Idreview.iloc[-1][0]               \n",
    "    return nuevo_indice\n",
    "\n",
    "\n",
    "cont = 0\n",
    "cont_max = 18 \n",
    "indice = 0\n",
    "for year in range(2005,2023):\n",
    "    # Visualizacion de avance\n",
    "    cont = cont + 1\n",
    "    clear_output(wait=True)\n",
    "    print('Completado: '+str(cont)+\"/\"+str(cont_max)+\"  \"+ str(round(cont / cont_max * 100, 2)) + '%')\n",
    "    \n",
    "    #Creacion de tabla 'Idreview.csv' y cambio de \"review_id\"(str)  por \"Id_review\"(int64)\n",
    "    if os.path.isfile(path+'\\\\'+nombre+\"_\"+str(year)+\".csv\"):\n",
    "        indice = creacion_Idreview(path+'\\\\'+nombre+\"_\"+str(year)+\".csv\",indice)\n",
    "\n",
    "#tiempo: 2 min "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_review</th>\n",
       "      <th>Iduser</th>\n",
       "      <th>Idbusiness</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4878585</td>\n",
       "      <td>143867</td>\n",
       "      <td>8313</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-04 02:18:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4878586</td>\n",
       "      <td>155207</td>\n",
       "      <td>11427</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-06 11:48:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4878587</td>\n",
       "      <td>84622</td>\n",
       "      <td>9889</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-27 15:08:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4878588</td>\n",
       "      <td>1210</td>\n",
       "      <td>9419</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-02-17 20:28:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4878589</td>\n",
       "      <td>190019</td>\n",
       "      <td>2376</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-17 17:17:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id_review  Iduser  Idbusiness  stars  useful  funny  cool  \\\n",
       "0    4878585  143867        8313      5       0      0     0   \n",
       "1    4878586  155207       11427      5       0      0     0   \n",
       "2    4878587   84622        9889      5       0      0     0   \n",
       "3    4878588    1210        9419      4       2      0     1   \n",
       "4    4878589  190019        2376      1       0      0     0   \n",
       "\n",
       "                  date  \n",
       "0  2019-01-04 02:18:09  \n",
       "1  2019-01-06 11:48:21  \n",
       "2  2019-01-27 15:08:14  \n",
       "3  2019-02-17 20:28:26  \n",
       "4  2019-02-17 17:17:56  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path+'\\\\review_2019.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_review</th>\n",
       "      <th>review_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ep8FfviAfqHNyhpW6MQ2jA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9eeoAUQEJDw0KYV5NPYH-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RcsyeHfZqpGdb9z-AkUdSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>JFjQ5RntPGhsNO2agAEYtg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MSt3hkzLBmIy8b8VwXlC7Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id_review               review_id\n",
       "0          0  ep8FfviAfqHNyhpW6MQ2jA\n",
       "1          1  9eeoAUQEJDw0KYV5NPYH-A\n",
       "2          2  RcsyeHfZqpGdb9z-AkUdSA\n",
       "3          3  JFjQ5RntPGhsNO2agAEYtg\n",
       "4          4  MSt3hkzLBmIy8b8VwXlC7Q"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path+'\\\\Idreview.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completado: 18/18  100.0%\n"
     ]
    }
   ],
   "source": [
    "#Primera corrida:\n",
    "#Se presentan los resultados finales en formato parquet en carpeta donde se esta corriendo el script\n",
    "# Para visualizacion de avance \n",
    "cont = 0\n",
    "cont_max = 18 \n",
    "for year in range(2005,2023):\n",
    "    # Visualizacion de avance\n",
    "    cont = cont + 1\n",
    "    clear_output(wait=True)\n",
    "    print('Completado: '+str(cont)+\"/\"+str(cont_max)+\"  \"+ str(round(cont / cont_max * 100, 2)) + '%')\n",
    "    \n",
    "    if os.path.isfile(path+'\\\\'+nombre+\"_\"+str(year)+\".csv\"):\n",
    "        df =pd.read_csv(path+'\\\\'+nombre+\"_\"+str(year)+\".csv\")\n",
    "        df.to_parquet(nombre+\"_\"+str(year)+'_parquet.gzip',compression='gzip')\n",
    "\n",
    "#conversion a parquet para que pese menos al almacenar\n",
    "df =pd.read_csv(path+'\\\\Idreview.csv')\n",
    "df.to_parquet('Idreview_parquet.gzip',compression='gzip') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En caso de hacer otra corrida con otro archivo .json se debe anexar la data que esta en la \n",
    "# carpeta path a la que se tanga anteriormente:\n",
    "cont = 0\n",
    "cont_max = 18 \n",
    "for year in range(2005,2023):\n",
    "    # Visualizacion de avance\n",
    "    cont = cont + 1\n",
    "    clear_output(wait=True)\n",
    "    print('Completado: '+str(cont)+\"/\"+str(cont_max)+\"  \"+ str(round(cont / cont_max * 100, 2)) + '%')\n",
    "    \n",
    "    if os.path.isfile(path+'\\\\'+nombre+\"_\"+str(year)+\".csv\"):\n",
    "        df =pd.read_csv(path+'\\\\'+nombre+\"_\"+str(year)+\".csv\")\n",
    "        ## por revisar porque tambien se puede hacer directamente en la carga MySQL \n",
    " \n",
    "df =pd.read_csv(path+'\\\\Idreview.csv')\n",
    "    ## por revisar porque tambien se puede hacer directamente en la carga MySQL \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completado: 18/18  100.0%\n"
     ]
    }
   ],
   "source": [
    "# Se borran archivos innecesarios en caso de requerirlo:\n",
    "from os import remove\n",
    "from os import rmdir\n",
    "cont = 0\n",
    "cont_max = 18\n",
    "for year in range(2005,2023):\n",
    "    # Visualizacion de avance\n",
    "    cont = cont + 1\n",
    "    clear_output(wait=True)\n",
    "    print('Completado: '+str(cont)+\"/\"+str(cont_max)+\"  \"+ str(round(cont / cont_max * 100, 2)) + '%')\n",
    "    if os.path.isfile(path+'\\\\'+nombre+\"_\"+str(year)+\".csv\"):\n",
    "        remove(path+'\\\\'+nombre+\"_\"+str(year)+\".csv\")\n",
    "        \n",
    "if os.path.isfile(path+'\\\\Idreview.csv'):\n",
    "    remove(path+'\\\\Idreview.csv')\n",
    "rmdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#al final de la corrida deben quedar los archivos reviewXXXX_parquet.gzip para armar la base de datos\n",
    "# y el archivo Idreview_parquet.gzip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78a5f5e9430e63759269e8e709c4002b1ad533978ca32d2fcf985e534411cec9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
