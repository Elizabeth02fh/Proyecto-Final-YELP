{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/probando/review_2018.csv')\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "# df.info()\n",
        "# Selecciona todas las columnas para las filas con índices entre 0 y 10\n",
        "df = df.iloc[:100]\n",
        "#We add a blank space before each review, because I didn't want to convert the first word of each review\n",
        "df.text = ' '+df.text\n",
        "\n",
        "#capitalize(): to change the first letter from a word to lowercase\n",
        "#strip(): to remove empty spaces from the left and right\n",
        "df.text = df.text.str.capitalize().str.strip()\n",
        "#df['text'] = df['text'].astype('string')\n",
        "# df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoYHdoERbeqy",
        "outputId": "5a5e3c26-8f6a-4682-8736-818792939eca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:5516: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[name] = value\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenización and stopword: gensim library"
      ],
      "metadata": {
        "id": "e87srH8AOMV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "\n",
        "df.text = df.text.apply(lambda x: remove_stopwords(x))\n",
        "#filtrar caracteres especiales dentro de un dataframe con la libreria re en python\n",
        "import re\n",
        "\n",
        "df.text = df.text.apply(lambda x: re.sub(\"[^a-zA-Z ]\",\"\",str(x)))\n",
        "df['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hS8eaI9ngi5O",
        "outputId": "62d257e5-ece0-4e2a-a4d7-dcb4d2bf5c27"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     decide eat here aware going  hours beginning e...\n",
              "1       stars one love th street naked tchopstix exc...\n",
              "2     boyfriend tried deli time today turkey avocado...\n",
              "3     amazing biscuits fill blank great cocktails to...\n",
              "4     cafe extremely cute came am jazz band playing ...\n",
              "                            ...                        \n",
              "95    ive times havent disappointed yet meat eaters ...\n",
              "96    place searching for friend tried nail salons t...\n",
              "97    unique professional and based experience opera...\n",
              "98    notch street tacos great service hand horchata...\n",
              "99    holy bat crap place amazing place st pete menu...\n",
              "Name: text, Length: 100, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemmer: Lematization"
      ],
      "metadata": {
        "id": "8s8RFGFgBNDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from textblob lib import Word method \n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from textblob import Word \n",
        "\n",
        "def lematizationn(texto):\n",
        "  lem = []\n",
        "  for i in texto.split():\n",
        "      word1 = Word(i).lemmatize(\"n\")\n",
        "      word2 = Word(word1).lemmatize(\"v\")\n",
        "      word3 = Word(word2).lemmatize(\"a\")\n",
        "      lem.append(Word(word3).lemmatize())\n",
        "  return lem\n",
        "df.text = df.text.apply(lambda x: lematizationn(x))\n",
        "df.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaRuQXugLrNf",
        "outputId": "bf95e41c-a123-4771-a458-4a006ec17ace"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     [decide, eat, here, aware, go, hour, begin, en...\n",
              "1     [star, one, love, th, street, naked, tchopstix...\n",
              "2     [boyfriend, try, deli, time, today, turkey, av...\n",
              "3     [amaze, biscuit, fill, blank, great, cocktail,...\n",
              "4     [cafe, extremely, cute, come, be, jazz, band, ...\n",
              "                            ...                        \n",
              "95    [ive, time, havent, disappoint, yet, meat, eat...\n",
              "96    [place, search, for, friend, try, nail, salon,...\n",
              "97    [unique, professional, and, base, experience, ...\n",
              "98    [notch, street, taco, great, service, hand, ho...\n",
              "99    [holy, bat, crap, place, amaze, place, st, pet...\n",
              "Name: text, Length: 100, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import nltk\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('word_tokenize')\n",
        "# from nltk.tokenize import word_tokenize \n",
        "\n",
        "# df['text'] = df['text'].astype('string')\n",
        "# df.text = df.text.apply(lambda x: word_tokenize(x))\n",
        "# df.text = df.text.apply(lambda x: nltk.FreqDist(x))\n",
        "# df.text\n",
        "# frecuency_each = pd.DataFrame(list(df.text.iloc[:3].items()), columns = [\"Word\",\"Frequency\"])\n",
        "# frecuency_each.head()"
      ],
      "metadata": {
        "id": "ciFp2s8_crMr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}