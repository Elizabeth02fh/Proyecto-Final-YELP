{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khorneflakes-dev/Proyecto-Final-YELP/blob/main/ETL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDZrrp1Q0vBf"
      },
      "source": [
        "unzip json files in to a folder in google drive cloud\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJWP_mm7jNsV"
      },
      "outputs": [],
      "source": [
        "# from zipfile import ZipFile\n",
        "# with ZipFile('drive/MyDrive/datasets.zip', 'r') as zipObj:\n",
        "  # zipObj.extractall('drive/MyDrive/test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEFE2Y0TooSx"
      },
      "source": [
        "import necessary libraries and setting pandas parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5STKBYXpunGd",
        "outputId": "9abc25da-27ea-4af5-8ee8-246066ae07ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymysql\n",
            "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: pymysql\n",
            "Successfully installed pymysql-1.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pymysql"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Vo4t-DUXlV9E"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sqlalchemy import create_engine\n",
        "import sqlalchemy\n",
        "from sqlalchemy.types import Integer, VARCHAR, Float\n",
        "pd.options.display.max_columns = None\n",
        "pd.set_option('display.max_rows', 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aDgs97JKQrF"
      },
      "source": [
        "### descripcion del data cleaning y el output esperado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG_SiweKxtEn"
      },
      "source": [
        "<img src = 'https://drive.google.com/uc?id=1-977aQbW7lqXx0dYfPwDFUIxVz5jxGnK'>\n",
        "\n",
        "df1: business_id, name, address, postal_code, latitude, longitude,stars, review_count, is_open => business\n",
        "\n",
        "df2: city, state => business_cities\n",
        "\n",
        "df3: attributes => business_attributes\n",
        "\n",
        "df4: categories => business_categories\n",
        "\n",
        "df5: hours => busines_hours"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b-IbfAMKGZ0"
      },
      "source": [
        "### definiendo la ruta input del archivo de carga incremental y el directorio de output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VqKMhhrhoDnw"
      },
      "outputs": [],
      "source": [
        "input_path = '/content/drive/MyDrive/yelp/Dataset Yelp/'\n",
        "df_business = pd.read_json(f'{input_path}business.json', lines=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE6DtNwAK0re"
      },
      "source": [
        "### funcion de transformacion del archivo original a uno que pueda alimentar la DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TMZRt0wPABlH"
      },
      "outputs": [],
      "source": [
        "def transform_business(df_business):\n",
        "  df_business = df_business.rename(columns={'business_id':'old_id'})\n",
        "  df_business['city'] = df_business['city'].apply(lambda x: x.lower())\n",
        "  df_business['city'] = df_business['city'].str.replace(',','')\n",
        "  df_business['city'] = df_business['city'].str.replace('.','')\n",
        "  df_business['city'] = df_business['city'].apply(lambda x: x.strip())\n",
        "  df_business['city'] = df_business['city'].apply(lambda x: \" \".join(x.split()))\n",
        "  df_business['city'] = df_business['city'].apply(lambda x: x.title())\n",
        "  df_business['categories'] = df_business['categories'].fillna('0')\n",
        "  cat_list = ['Restaurants', 'Hotels & Travel', 'Food', 'Nightlife', 'Active Life', 'Arts & Entertainment', 'Beauty & Spas']\n",
        "\n",
        "  def validator(value):\n",
        "    if value in cat_list:\n",
        "      return 1000\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  def cat_to_list(value):\n",
        "    value = value.split(', ')\n",
        "    value.sort(key=validator, reverse=True)\n",
        "    return ', '.join(value)\n",
        "  \n",
        "  df_business['categories'] = df_business['categories'].apply(lambda x: cat_to_list(x))\n",
        "\n",
        "  city_dict = {'Belle Chase': 'Belle Chasse', 'Abington Township': 'Abington','Ashland City': 'Ashland','Bellefontaine Neighbors': 'Bellefontaine',\n",
        "               'Bellville': 'Belleville','Belleair Blf': 'Belleair Bluffs','Bethel Township': 'Bethel','Bensalem Pa': 'Bensalem',\n",
        "               'Bensalem Township': 'Bensalem','Boise City': 'Boise','Burlington Township': 'Burlington',\"Carney'S Point\": 'Carneys Point',\n",
        "               'Cedar Brook': 'Cedarbrook','/': '','Conshohoeken':'Conshohocken','Delran Township': 'Delran','Delran Twp': 'Delran',\n",
        "               'Concord Township': 'Concord','Deptford Township': 'Deptford','Eastampton Township': 'Eastampton',' Township': '',\n",
        "               'Fairview Hts': 'Fairview','-': '',' City': '',' Twp': '','Bch': 'Beach','Land O Lakes':\"Land O'Lakes\",\"Land O' Lakes\":\"Land O'Lakes\",\n",
        "               'Mccordsville': 'Mc Cordsville','Metarie': 'Metairie','Mt Laurel Twp Nj': 'Mt Laurel','Sqaure': 'Square','O Fallon': \"O'Fallon\",\n",
        "               \"O' Fallon\": \"O'Fallon\",'Phila': 'Philadelphia','Philadephia': 'Philadelphia','Philly': 'Philadelphia',\n",
        "               'Redingtn Shor': 'Redington Shore','Redington Shores': 'Redington Shore','Riverview Fl': 'Riverview','Saintt': 'Saint',\n",
        "               'Tierre': 'Tierra',\"Town 'N' Country\": 'Town & Country','Town And Country': 'Town & Country','Town N Country': 'Town & Country',\n",
        "               'Tuscon': 'Tucson'\n",
        "             }\n",
        "\n",
        "  df_business = df_business.replace({'city': city_dict})\n",
        "  df_restaurants = df_business[df_business['categories'].str.contains('Restaurant')]\n",
        "  df_city_state = df_business[['city', 'state']].drop_duplicates().copy()\n",
        "  new_col2 = list(range(1, len(df_city_state)+1, 1))\n",
        "  df_city_state.insert(loc = 0, column = 'city_state_id', value = new_col2) \n",
        "\n",
        "  df2 = pd.merge(df_business, df_city_state, left_on=['city', 'state'], right_on=['city', 'state'], how='left')\n",
        "  df_business['city_state_id'] = df2['city_state_id']\n",
        "  def cat_to_col(value):\n",
        "    aux_dict = {}\n",
        "    x = value.split(', ')\n",
        "    for i in x:\n",
        "      aux_dict[i] = 1\n",
        "    return aux_dict\n",
        "  def dict_to_columns(df_i, column):\n",
        "    df_i[column] = df_i[column].fillna('{}')\n",
        "    df_i.reset_index(inplace=True)\n",
        "    df_o = df_i.join(pd.json_normalize(df_i.pop(column)))\n",
        "    if 'level_0' in df_o.columns:\n",
        "      df_o.drop(['level_0'], axis=1, inplace=True)\n",
        "\n",
        "    return df_o\n",
        "  def attr_to_list(i):\n",
        "    attributes_list = []\n",
        "    try:\n",
        "      for j in i:\n",
        "        if i[j] == 'True' or i[j] == '1' or i[j] == \"u'free'\":\n",
        "          attributes_list.append(j)\n",
        "      return ', '.join(attributes_list)\n",
        "    except:\n",
        "      return ''\n",
        "  df_restaurants['attributes'] = df_restaurants['attributes'].apply(lambda x: attr_to_list(x))\n",
        "  df_business['attributes'] = df_business['attributes'].apply(lambda x: attr_to_list(x))\n",
        "  df_business = df_business[df_business['categories'].str.contains('Restaurants|Hotels & Travel|Food|Nightlife|Active Life|Arts & Entertainment|Beauty & Spas')]\n",
        "  df_business = df_business.reset_index(drop=True)\n",
        "\n",
        "\n",
        "  business_index = pd.DataFrame()\n",
        "  business_index['id'] = list(range(1, len(df_business) + 1, 1))\n",
        "  business_index['business_id'] = df_business['old_id'].copy()\n",
        "\n",
        "  df_business.drop(['old_id'], axis=1, inplace=True)\n",
        "  new_col = list(range(1, len(df_business) +1, 1))\n",
        "  df_business.insert(loc = 0, column = 'business_id', value = new_col)\n",
        "\n",
        "\n",
        "  df_hours = pd.DataFrame()\n",
        "  df_hours['hours'] = df_business['hours'].copy()\n",
        "  df_hours['aux'] = df_hours['hours'].astype('str')\n",
        "  df_hours = dict_to_columns(df_hours, 'hours')\n",
        "  df_hours = df_hours.fillna(0)\n",
        "  df_hours.drop(['index'], axis=1, inplace=True)\n",
        "  df_hours = df_hours.drop_duplicates()\n",
        "  df_hours.insert(loc = 0, column = 'hours_id', value = list(range(1, len(df_hours)+1, 1)))\n",
        "  df_business['hours'] = df_business['hours'].astype('str')\n",
        "  df3=pd.merge(df_business,df_hours, left_on='hours', right_on='aux', how='inner')\n",
        "  df3.drop(['hours','aux','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'], axis=1, inplace=True)\n",
        "  df_business['hours_id'] = df3['hours_id']\n",
        "  df_business.drop(['hours'], axis=1, inplace=True)\n",
        "  df_business['attributes'] = df_business['attributes'].astype('str')\n",
        "  \n",
        "  df_attributes = pd.DataFrame()\n",
        "  df_attributes['attributes'] = df_business['attributes']\n",
        "  df_attributes = df_attributes.drop_duplicates()\n",
        "  df_attributes.insert(loc = 0, column = 'attributes_id', value = list(range(1, len(df_attributes)+1)))\n",
        "  df_attributes['attributes'] = df_attributes['attributes'].astype('str')\n",
        "  df5 = pd.merge(df_business, df_attributes, left_on=['attributes'], right_on=['attributes'], how='inner')\n",
        "  df_business['attributes_id'] = df5['attributes_id']\n",
        "  df_categories = pd.DataFrame()\n",
        "  df_categories['categories'] = df_business['categories']\n",
        "  df_categories = df_categories.drop_duplicates()\n",
        "  df_categories.insert(loc = 0, column = 'categories_id', value = list(range(1, len(df_categories)+1, 1)))\n",
        "  df6 = pd.merge(df_business, df_categories, left_on='categories', right_on='categories', how='inner')\n",
        "  df_business['categories_id'] = df6['categories_id']\n",
        "  df_business.drop(['city', 'state', 'attributes','categories'], axis=1, inplace=True)\n",
        "  df_hours.drop(['aux'], axis=1, inplace=True)\n",
        "  hours_aux = df_hours.columns.tolist()[1:]\n",
        "  for i in hours_aux:\n",
        "    df_hours[i] = df_hours[i].astype('str')\n",
        "\n",
        "  # definiendo los formatos de columnas\n",
        "\n",
        "  #business\n",
        "  dtypes1 = {'business_id': Integer,'name': VARCHAR(255),'address': VARCHAR(255),'postal_code': VARCHAR(25),'latitude': Float,'longitude': Float,'stars': Float,\n",
        "             'review_count': Integer,'is_open': Integer,'city_state_id': Integer,'hours_id': Integer,'attributes_id': Integer,'categories_id': Integer}\n",
        "\n",
        "  # attributes\n",
        "  dtypes2 = { 'attributes_id': Integer}\n",
        "\n",
        "  # categories\n",
        "  dtypes3 = { 'categories_id': Integer, 'categories': VARCHAR(655) }\n",
        "\n",
        "  # city_state\n",
        "  dtypes4 = {'city_state_id': Integer,'city': VARCHAR(100),'state': VARCHAR(10)}\n",
        "\n",
        "  # hours\n",
        "  dtypes5 = { 'hours_id': Integer, 'Monday': VARCHAR(25), 'Tuesday': VARCHAR(25), 'Wednesday': VARCHAR(25), 'Thursday': VARCHAR(25), 'Friday': VARCHAR(25), 'Saturday': VARCHAR(25), 'Sunday': VARCHAR(25)}\n",
        "\n",
        "\n",
        "  engine = create_engine('mysql+pymysql://root:projectyelp2022@34.176.218.33/projectyelp')\n",
        "\n",
        "  df_attributes['attributes'] = df_attributes['attributes'].str.replace('','', regex=True)\n",
        "  \n",
        "  df_business.to_sql('business', con=engine, index=False, if_exists='replace', dtype=dtypes1)\n",
        "  print('terminado 1')\n",
        "  df_attributes.to_sql('business_attributes', con=engine, index=False, if_exists='replace', dtype=dtypes2)\n",
        "  print('terminado 2')\n",
        "  df_categories.to_sql('business_categories', con=engine, index=False, if_exists='replace', dtype=dtypes3)\n",
        "  print('terminado 3')\n",
        "  df_city_state.to_sql('business_city_state', con=engine, index=False, if_exists='replace', dtype=dtypes4)\n",
        "  print('terminado 4')\n",
        "  df_hours.to_sql('business_hours', con=engine, index=False, if_exists='replace', dtype=dtypes5)\n",
        "  print('terminado 5')\n",
        "\n",
        "  business_index.to_sql('business_index', con=engine, index=False, if_exists='replace', dtype={'id': Integer})\n",
        "  print('terminado index business')\n",
        "  \n",
        "  \n",
        "  engine.dispose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mmamsZPt2Zb"
      },
      "source": [
        "#### separando el archivo original en carga inicial e incremental\n",
        "#### ejecutando el script para carga inicial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLbI1rMAt7N1",
        "outputId": "b856b6c0-d47c-4415-f98b-6d8f342506d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "terminado 1\n",
            "terminado 2\n",
            "terminado 3\n",
            "terminado 4\n",
            "terminado 5\n",
            "terminado index business\n",
            "business_index add PK\n"
          ]
        }
      ],
      "source": [
        "transform_business(df_business)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edldFCcMEXQm"
      },
      "source": [
        "### pdf reporte"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAVsARK_uq_I"
      },
      "source": [
        "#### reporte de calidad de datos business"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOGiOsVsC92a",
        "outputId": "f84f4bbb-c2d0-46ef-8a0e-f0efb62e1fb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40721 sha256=5c11da8633f2f13db312b4f72c1c1999ae9fe468c316bf70c1f3e6d99a75c842\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/ca/c8/86467e7957bbbcbdf4cf4870fc7dc95e9a16404b2e3c3a98c3\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install fpdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fM8IujdVDBk6"
      },
      "outputs": [],
      "source": [
        "from fpdf import FPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YX4u5RFjDMuX",
        "outputId": "2b6466ca-b1ab-4542-92d4-4ccc229fa1f0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdf = FPDF(orientation='P', unit='mm', format='A4')\n",
        "\n",
        "pdf.add_page()\n",
        "pdf.set_font('Arial', '', 16)\n",
        "pdf.text(x=10, y=50, txt='hola mundo')\n",
        "\n",
        "pdf.output('/content/drive/MyDrive/yelp/demo.pdf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSq14xcRT-zD"
      },
      "source": [
        "### user data load (JC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "esak7i7tT-zE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#!pip install pymysql\n",
        "import pymysql\n",
        "import sqlalchemy as db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PxbNy4xHT-zE"
      },
      "outputs": [],
      "source": [
        "#establecimiento de conexión con la base de datos pi_1\n",
        "database_username='root' # Nombre de cliente en MySQL Workbench\n",
        "database_password='projectyelp2022' # Contraseña de MySQL Workbench\n",
        "database_ip='34.176.218.33' # localizacion del servidor\n",
        "database_name='projectyelp' # Nombre de Base de datos a la que nos conectaremos\n",
        "engine=db.create_engine(f'mysql+pymysql://{database_username}:{database_password}@{database_ip}/{database_name}')\n",
        "conexion=engine.connect()\n",
        "meta = db.MetaData()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IiSGTMpqT-zE"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy.dialects.mysql import MEDIUMTEXT\n",
        "users = db.Table(\n",
        "    'users' , meta,\n",
        "    db.Column('n_user_id',db.INTEGER),\n",
        "    db.Column('review_count',db.INTEGER),\n",
        "    db.Column('yelping_since',db.DATE),\n",
        "    db.Column('useful',db.INTEGER),\n",
        "    db.Column('funny',db.INTEGER),\n",
        "    db.Column('cool',db.INTEGER),\n",
        "    db.Column('friends', MEDIUMTEXT),\n",
        "    db.Column('fans',db.INTEGER),\n",
        "    db.Column('average_stars',db.DECIMAL(precision=3, scale=2))    \n",
        ")\n",
        "meta.create_all(engine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "AqVRdy9qT-zE"
      },
      "outputs": [],
      "source": [
        "def etl_users(chunk):\n",
        "    col_to_drop=['name','elite','compliment_hot','compliment_more', 'compliment_profile', 'compliment_cute', 'compliment_list', 'compliment_note', 'compliment_plain',\n",
        "                'compliment_cool', 'compliment_funny', 'compliment_writer','compliment_photos'] # droppable columns list\n",
        "    data_types={'average_stars':np.float32 , 'fans':'uint16', 'review_count':'uint16', 'cool':'uint32', 'useful':'uint32', 'funny':'uint32'} # data types dict for some columns\n",
        "    \n",
        "    chunk = chunk.drop(columns=col_to_drop).astype(data_types)\n",
        "    chunk.insert(1, 'n_user_id', value = list(range(chunk.index.start+1, chunk.index.stop+1)))\n",
        "    chunk.yelping_since = pd.to_datetime(chunk.yelping_since, format='%Y-%m-%d %H:%M:%S')\n",
        "    chunk = chunk.astype({'n_user_id':'uint32'})\n",
        "    return chunk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DurTbuhMT-zE",
        "outputId": "f919c4bc-827c-48d2-eac2-b2ae9d31e0ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "sql_data_types={ \n",
        "'n_user_id':db.types.INTEGER, \n",
        "'review_count': db.types.INTEGER,\n",
        "'yelping_since': db.types.DATE,\n",
        "'useful': db.types.INTEGER,                 \n",
        "'funny' : db.types.INTEGER,        \n",
        "'cool' : db.types.INTEGER,       \n",
        "'friends' : MEDIUMTEXT,       \n",
        "'fans' : db.types.INTEGER,        \n",
        "'average_stars': db.types.DECIMAL(precision=3, scale=2)\n",
        "}\n",
        "\n",
        "reader = pd.read_json(\"drive/MyDrive/yelp/Dataset Yelp/user.json\" , lines=True , chunksize=400000) # definition of the iterator reader object\n",
        "chunks_codes=[] # define empty list for chunks\n",
        "for chunk in reader:  #iterate over the reader object users\n",
        "  iter_chunk = etl_users(chunk)\n",
        "  chunks_codes.append(iter_chunk[['user_id', 'n_user_id']])  # append modified chunks into the chunks list \n",
        "  iter_chunk.drop(columns=['user_id'], inplace=True)\n",
        "  iter_chunk.to_sql('users',conexion, index=False , dtype=sql_data_types, if_exists='append')\n",
        "  print(len(chunks_codes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "N6CjTP1dT-zE"
      },
      "outputs": [],
      "source": [
        "users_ids= pd.concat(chunks_codes)  # get the user_codes dataframe\n",
        "\n",
        "# load of users_ids table to cloud sql\n",
        "codes_data_types={ \n",
        "'user_id': db.types.NVARCHAR(70),\n",
        "'n_user_id':db.types.INTEGER\n",
        "}\n",
        "users_ids.to_sql('users_ids',conexion, index=False , dtype=codes_data_types, if_exists='replace')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyraOIgeT-zF",
        "outputId": "5cd90156-8441-41cb-f65d-3e5556a2be3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x7fc8f7b042d0>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# setting primary auto_incremental keys and foreign keys\n",
        "auto_increment_init = users_ids.shape[0]\n",
        "conexion.execute(f\"ALTER TABLE users_ids CHANGE COLUMN `n_user_id` `n_user_id` INT NOT NULL AUTO_INCREMENT PRIMARY KEY, AUTO_INCREMENT = {auto_increment_init+1};\")\n",
        "conexion.execute(f\"ALTER TABLE users CHANGE COLUMN `n_user_id` `n_user_id` INT NOT NULL AUTO_INCREMENT PRIMARY KEY, AUTO_INCREMENT = {auto_increment_init+1};\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qFEI0s1HT-zF"
      },
      "outputs": [],
      "source": [
        "# to save RAM\n",
        "del chunks_codes\n",
        "del chunk\n",
        "del iter_chunk\n",
        "del reader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8JAV-xET-zF"
      },
      "source": [
        "ETL reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IIWXymUZT-zF"
      },
      "outputs": [],
      "source": [
        "rdb = conexion.execute(f\"select * from business_index\")\n",
        "codes_b = pd.DataFrame(rdb.fetchall())\n",
        "codes_b.columns = rdb.keys()\n",
        "\n",
        "rdb = conexion.execute(f\"select * from users_ids\")\n",
        "codes_u = pd.DataFrame(rdb.fetchall())\n",
        "codes_u.columns = rdb.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "8ZHbdQePT-zF"
      },
      "outputs": [],
      "source": [
        "df_business_id = codes_b\n",
        "df_user_id = codes_u\n",
        "del codes_b\n",
        "del codes_u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "TUF2A38xT-zF"
      },
      "outputs": [],
      "source": [
        "#funcion de transformación para pasar al chunk\n",
        "\n",
        "def review_etl(df):\n",
        "  df.drop(['text'], axis=1, inplace=True)\n",
        "  df_aux = pd.merge(df, df_business_id, left_on='business_id', right_on='business_id', how='inner')\n",
        "  df_aux.drop(['business_id'], axis=1, inplace=True)\n",
        "  df_aux = df_aux.rename(columns={\"id\": \"id_business\"})\n",
        "\n",
        "  df_aux2 = pd.merge(df_aux, df_user_id, left_on='user_id', right_on='user_id', how='inner')\n",
        "  df_aux2.drop(['user_id'], axis=1, inplace=True)\n",
        "  df_aux2.drop(['useful','funny','cool'], axis=1, inplace=True)\n",
        "  df_aux2 = df_aux2.rename(columns={\"n_user_id\": \"id_user\"})\n",
        "  \n",
        "  df_aux2.reset_index(drop=True)\n",
        "  \n",
        "  df_aux2['date']= pd.to_datetime(df_aux2['date'])\n",
        "  df_aux2['year'] = df_aux2['date'].dt.year\n",
        "  df_aux2['month'] = df_aux2['date'].dt.month\n",
        "  \n",
        "  return df_aux2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTVPKNUHT-zG",
        "outputId": "f0f444c1-6136-4e1e-fa0e-cac9d984ec9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "360773\n",
            "698635\n",
            "1053154\n",
            "1396649\n",
            "1744485\n",
            "2095958\n",
            "2429215\n",
            "2785293\n",
            "3118726\n",
            "3468670\n",
            "3813854\n",
            "4154707\n",
            "4510792\n",
            "4844585\n",
            "5204542\n",
            "5542106\n",
            "5895024\n",
            "6048057\n"
          ]
        }
      ],
      "source": [
        "path = '/content/drive/MyDrive/yelp/Dataset Yelp/review.json'\n",
        "main_chunk = pd.read_json(path, lines=True, chunksize=400000)\n",
        "\n",
        "conteo_ind_inicial=1\n",
        "chunks_codes = []\n",
        "for chunk in main_chunk:\n",
        "  iter_chunk = review_etl(chunk)\n",
        "  iter_chunk.insert(1, 'id_review', value = list(range(conteo_ind_inicial, conteo_ind_inicial+iter_chunk.shape[0])))\n",
        "  conteo_ind_inicial += iter_chunk.shape[0]\n",
        "  chunks_codes.append(iter_chunk[['review_id', 'id_review']])  # append modified chunks into the chunks list \n",
        "  iter_chunk.drop(columns=['review_id'], inplace=True)\n",
        "  iter_chunk.to_sql('reviews',conexion, index=False , if_exists='append')\n",
        "  print(conteo_ind_inicial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "CO7wM5DsT-zG"
      },
      "outputs": [],
      "source": [
        "idreviews = pd.concat(chunks_codes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "HSBquiz7T-zG"
      },
      "outputs": [],
      "source": [
        "\n",
        "# load of users_ids table to cloud sql\n",
        "idreviews.to_sql('idreviews',conexion, index=False , if_exists='replace')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RX-yBtzrT-zG",
        "outputId": "88a09884-8469-4f49-8baf-fc98bf564cd3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x7fc8f7a77690>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# set primary keys to tables idreviews and reviews\n",
        "auto_increment_init = idreviews.shape[0]\n",
        "conexion.execute(f\"ALTER TABLE idreviews CHANGE COLUMN `id_review` `id_review` INT NOT NULL AUTO_INCREMENT PRIMARY KEY, AUTO_INCREMENT = {auto_increment_init+1};\")\n",
        "conexion.execute(f\"ALTER TABLE reviews CHANGE COLUMN `id_review` `id_review` INT NOT NULL AUTO_INCREMENT PRIMARY KEY, AUTO_INCREMENT = {auto_increment_init+1};\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OWdwd8RT-zG"
      },
      "outputs": [],
      "source": [
        "del chunks_codes\n",
        "del chunk\n",
        "del iter_chunk\n",
        "del main_chunk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM4nwfdrewJS"
      },
      "source": [
        "### missing connections between tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ncFAFHuhQNA",
        "outputId": "07b4290e-5f97-4090-fc3a-c114b797797f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x7fc8f7a2c8d0>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# set primary keys to tables business and business_index\n",
        "qdb = conexion.execute('SELECT max(business_id) FROM projectyelp.business;').fetchone()\n",
        "conexion.execute(f\"ALTER TABLE business CHANGE COLUMN `business_id` `business_id` INT NOT NULL AUTO_INCREMENT PRIMARY KEY, AUTO_INCREMENT = {qdb[0] + 1};\")\n",
        "conexion.execute(f\"ALTER TABLE business_index CHANGE COLUMN `id` `id` INT NOT NULL AUTO_INCREMENT PRIMARY KEY, AUTO_INCREMENT = {qdb[0] + 1};\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCVxkKm_pT3w",
        "outputId": "b33d623e-ec27-4ad7-bdcd-6090c539f9d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x7fc8f8a4c9d0>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# set primary key on tables related with business\n",
        "qdb = conexion.execute('SELECT max(attributes_id) FROM projectyelp.business_attributes;').fetchone()\n",
        "conexion.execute(f\"ALTER TABLE business_attributes CHANGE COLUMN `attributes_id` `attributes_id` INT NOT NULL AUTO_INCREMENT PRIMARY KEY, AUTO_INCREMENT = {qdb[0] + 1};\")\n",
        "\n",
        "qdb = conexion.execute('SELECT max(categories_id) FROM projectyelp.business_categories;').fetchone()\n",
        "conexion.execute(f\"ALTER TABLE business_categories CHANGE COLUMN `categories_id` `categories_id` INT NOT NULL AUTO_INCREMENT PRIMARY KEY, AUTO_INCREMENT = {qdb[0] + 1};\")\n",
        "\n",
        "qdb = conexion.execute('SELECT max(city_state_id) FROM projectyelp.business_city_state;').fetchone()\n",
        "conexion.execute(f\"ALTER TABLE business_city_state CHANGE COLUMN `city_state_id` `city_state_id` INT NOT NULL AUTO_INCREMENT PRIMARY KEY, AUTO_INCREMENT = {qdb[0] + 1};\")\n",
        "\n",
        "qdb = conexion.execute('SELECT max(hours_id) FROM projectyelp.business_hours;').fetchone()\n",
        "conexion.execute(f\"ALTER TABLE business_hours CHANGE COLUMN `hours_id` `hours_id` INT NOT NULL AUTO_INCREMENT PRIMARY KEY, AUTO_INCREMENT = {qdb[0] + 1};\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN-xgvqtsBqR",
        "outputId": "bbbb7e5c-6175-4983-9c0e-35bfbd33c3dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x7fc8f79baa50>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# set foreign keys on business table with all its secondary dimensional tables\n",
        "conexion.execute(\"ALTER TABLE `projectyelp`.`business` ADD CONSTRAINT `business_attributes`   FOREIGN KEY (`attributes_id`)   REFERENCES `projectyelp`.`business_attributes` (`attributes_id`)   ON DELETE NO ACTION   ON UPDATE NO ACTION;\")\n",
        "conexion.execute(\"ALTER TABLE `projectyelp`.`business` ADD CONSTRAINT `business_categories`   FOREIGN KEY (`categories_id`)   REFERENCES `projectyelp`.`business_categories` (`categories_id`)   ON DELETE NO ACTION   ON UPDATE NO ACTION;\")\n",
        "conexion.execute(\"ALTER TABLE `projectyelp`.`business` ADD CONSTRAINT `business_city_state`   FOREIGN KEY (`city_state_id`)   REFERENCES `projectyelp`.`business_city_state` (`city_state_id`)   ON DELETE NO ACTION   ON UPDATE NO ACTION;\")\n",
        "conexion.execute(\"ALTER TABLE `projectyelp`.`business` ADD CONSTRAINT `business_hours`   FOREIGN KEY (`hours_id`)   REFERENCES `projectyelp`.`business_hours` (`hours_id`)   ON DELETE NO ACTION   ON UPDATE NO ACTION;\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82fhLYanerdf",
        "outputId": "598b2186-b4de-42eb-a9db-989e4b9ab269"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x7fc8f7ae6c90>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# PENDIENTE para que el siguiente codigo funcione las claves foraneas de la tabla reviews  deben cambiarse de bigint a int\n",
        "conexion.execute(\"ALTER TABLE `projectyelp`.`reviews` ADD CONSTRAINT `reviews_users`   FOREIGN KEY (`id_user`)   REFERENCES `projectyelp`.`users` (`n_user_id`)   ON DELETE NO ACTION   ON UPDATE NO ACTION;\")\n",
        "conexion.execute(\"ALTER TABLE `projectyelp`.`reviews` ADD CONSTRAINT `reviews_business`   FOREIGN KEY (`id_business`)   REFERENCES `projectyelp`.`business` (`business_id`)   ON DELETE NO ACTION   ON UPDATE NO ACTION;\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "jwhusXYyT-zG"
      },
      "outputs": [],
      "source": [
        "conexion.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "1aDgs97JKQrF"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 ('Proyecto-Final-YELP-Us21KoUz')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "5a2230d546b76f8d6d8920d479c809d384b49ecfda9fd3e60bed90ca330c4d6d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
